---
title: "NBA Shot Project"
author: "Chris Williams"
date: "August 20, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
```

```{r package}
library(tidyverse)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r read_data}
shots <- read_csv("nba_shots.csv")
summary(shots)
str(shots)
shots <- shots %>% mutate(player_name = map_chr(shots$player_name, str_to_title))
totals <- read_csv("totals_1415.csv")
str(totals)
into_names <- names(totals) %>% str_split(",") %>% .[[1]]
names(totals) <- "x"
totals <- totals %>% separate(x, into_names, sep = ",")
totals <- as_tibble(totals)
head(totals)
positions <- totals %>% select(c("Player", "Pos"))
```

```{r explore_data_positions}
##need lubridate because GAME_CLOCK is time
library(lubridate)
summary(positions)
nrow(positions) - n_distinct(positions$Player) #duplicate players from being on different teams
n_distinct(positions$Pos) #will need to handle this later, there are dual positions
#Keeping only distinct players because I just want position info
positions <- positions %>% distinct(Player, .keep_all = TRUE)
sum(is.na(positions$Player))
positions[which(is.na(positions$Player)),]
positions <- positions %>% drop_na() %>% mutate(rid = row_number())
##dropped a reference line of where the data came from while adding a row id number "unique identifier"
#checking to see what characters are part of player column
unique(unlist(str_split(positions$Player, "")))
positions[str_which(positions$Player, "\\\\.*"),]
## "\\appears before some kind of id name for all players so I want to remove this and the id name"
positions$Player <- str_replace_all(positions$Player, "\\\\.*", "")
#accent marks are not represented so index these
bad_char <- positions[str_which(positions$Player, "[\\?\uFFFD]"),]
#after a quick view, "?" at the end is a "c"
positions$Player <- if_else(str_detect(positions$Player, "\\?$"), str_replace(positions$Player, "\\?$", "c"), positions$Player)
#index what is remaining and there isn't any real overlap to allow for an effective ifelse...
bad_char_remain <- positions[str_which(positions$Player, "[\\?\uFFFD]"),]
fixed_pname <- c("Alexis Ajinca", "Omer Asik", "Jose Calderon", "Francisco Garcia", "Manu Ginobili", "Jorge Gutierrez", "Nene Hilario", "Ersan Ilyasova", "Donatas Motiejunas", "Damjan Rudez", "Dennis Schroder", "Kevin Seraphin", "Hedo Turkoglu", "Jonas Valanciunas", "Anderson Varejao", "Greivis Vasquez", "Nikola Vucevic")
positions$Player <- plyr::mapvalues(positions$Player, from = bad_char_remain$Player, to = fixed_pname)
#check what characters remain
unique(unlist(str_split(positions$Player, "")))
#fix players with multiple positions
positions[str_which(positions$Pos, ".{3,}"),]
positions$Pos <- str_replace_all(positions$Pos, "^(..)-(..)$", "\\1")
#although position does not guarentee height, speed, etc..., greater "distance" between the positions of shooters and defenders should represent "mismatch" scenarios.
#prepare for merging
positions <- rename(positions, "player_name" = "Player")
```
###now move onto shots...
```{r explore_data_shots}
n_distinct(shots$player_name)
player_list_shooter <- shots %>% distinct(player_name)
no_match_shots <- player_list_shooter %>% anti_join(positions, by = "player_name")
fixed_pname_2 <- c("Joe Ingles", "DeMarre Carroll", "Jimmer Fredette", "Monta Ellis", "J.J. Barea", "Al-Farouq Aminu", "Dirk Nowitzki", "Kyle O'Quinn", "LeBron James", "C.J. Watson", "C.J. Miles", "Danilo Gallinari", "J.J. Hickson", "P.J. Tucker", "Nerlens Noel", "K.J. McDaniels", "JaKarr Sampson", "Luc Mbah a Moute", "O.J. Mayo", "Beno Udrih", "Amar'e Stoudemire", "Tim Hardaway", "D.J. Augustin", "Dwyane Wade", "Ray McCallum", "Ben McLemore", "DeMarcus Cousins", "Steven Adams", "J.J. Redick", "DeAndre Jordan", "CJ McCollum", "LaMarcus Aldridge", "Allen Crabbe", "Zach LaVine")
shots$player_name <- plyr::mapvalues(shots$player_name, from = no_match_shots$player_name, to = fixed_pname_2)
#check the success of the join
shots %>% distinct(player_name) %>% anti_join(positions, by = "player_name")
#check some data quality starting with
#ranges
shots_ranges <- map(shots, ~range(.))
#NAs
shots_na <- map(shots, ~sum(is.na(.))) %>% unlist()
#shot_clock is the only column with NAs
#persumably these are mostly situations in which the shot clock is off (i.e., end of quarters)
shots_ranges$GAME_CLOCK
#time difference in seconds, but parsed as hours, minutes, seconds
#game clock is measured within quarter (would need to pair with period to get game time across quarters)
shots <- shots %>% mutate(qtr_seconds = (seconds(GAME_CLOCK)/60))
shots %>% filter(qtr_seconds > 24 & is.na(SHOT_CLOCK))
#clearly many instances in which shot clock data is missing and is NOT the end of a quarter
#it is possible that these situations represent "immediate" putbacks or shots off of rebounds when shot clock gets reset (but shot clock should still be recorded) or shots off of turnovers or shots "launched" from across court
shots %>% filter(is.na(SHOT_CLOCK) & qtr_seconds > 24 & TOUCH_TIME <= 1) %>% nrow(.)
#this would "save" 783 shots/rows of data by allowing for no reset of the shot clock on a "fast" rebound+shot or a loose ball and then fast shot
#could also filter by dribbles b/c shot clock should have time to reset when dribble is greater than zero or 1
shots %>% filter(is.na(SHOT_CLOCK) & qtr_seconds > 24 & TOUCH_TIME <= 1 & DRIBBLES >= 1) %>% group_by(DRIBBLES) %>% tally()
#there are 14 such cases but because touch time is less than or equal to 1 and dribbles is not greater than 1 (which would suggest an error in the data) these cases can be kept
#but lets look at what those "fast" shots are like
shots %>% filter(is.na(SHOT_CLOCK) & qtr_seconds > 24 & TOUCH_TIME <= 1) %>%
  ggplot(aes(SHOT_DIST)) +
  geom_freqpoly()
#the distribution of fast shots seems to match that of all shots in terms of shot distance
#what about the others that don't seem to fit within a "fast" shot
shots %>% filter(is.na(SHOT_CLOCK) & qtr_seconds > 24 & TOUCH_TIME > 1)
shots %>% filter(is.na(SHOT_CLOCK) & qtr_seconds > 24 & TOUCH_TIME > 1) %>% group_by(player_name) %>% tally() %>% arrange(desc(`n`))
#this isn't an issue for one player or group of players, almost all players 
shots %>% filter(is.na(SHOT_CLOCK) & qtr_seconds > 24 & TOUCH_TIME > 1) %>%
  ggplot(aes(SHOT_DIST)) +
  geom_freqpoly()
#dropping all of these would be over 1200 shots
shots <- shots %>% filter(!(qtr_seconds > 24 & is.na(SHOT_CLOCK) & TOUCH_TIME > 1))
#now the NAs can be replaced with a "shot clock" vlaue based on game clock if needed
#may not want to do this yet with end of quarter, shot clock "off" shots, but can do it for "fast shots" assigning a 24 when appropriate 
shots[is.na(shots$SHOT_CLOCK) & shots$qtr_seconds > 24, 9] <- 24
shots_ranges$TOUCH_TIME
#a touch time of 0 isn't necessarily an error if it is measured as touch time other than shooting
#because there was no description of what touch time represents I will explore
#negative touch time is not possible and must be an error and should be dropped (lose over 300 shots)
shots %>% filter(TOUCH_TIME < 0) %>% nrow(.)
shots <- shots %>% filter(TOUCH_TIME >= 0)
shots %>% filter(TOUCH_TIME == 0)
shots %>% filter(TOUCH_TIME == 0 & DRIBBLES > 0)
#only a couple of instances where dribble is more than 1, but only 10 instances total
#the 1 dribbles will remain because those are "realistic" based on game time, shot clock, etc...
#the 2 and 3 dribble cases will be dropped
shots <- shots %>% filter(!(TOUCH_TIME == 0 & DRIBBLES > 1))
#IF going to replace with mean
###shots %>% filter(TOUCH_TIME > 0) %>% group_by(DRIBBLES) %>% summarize(ave_tt = mean(TOUCH_TIME), sd_tt = sd(TOUCH_TIME), cnt = n()) %>% filter(cnt > 40)
#knn imputation would be
#library(VIM)
#shots$TOUCH_TIME[shots$TOUCH_TIME <= 0 & shots$DRIBBLES > 0] <- NA
#shots <- kNN(shots, variable = "TOUCH_TIME") but this does not take care of the large number of 0s
#touch time should never be negative and the 3000 or so 0s is concerning if it supposed to include shooting time;
##however those probably represent tips or catch and shoot situations
#could also used the means like in the line above, but knn produces consistently lower values and sd tends to be greater than 1 but around 1.15-1.35 for each dribble
#drop shots that aren't "realistic" or consistent with pts type
#all shots are within length of the court
shots_ranges$SHOT_DIST
#appears all shots are from half court or closer
#no information avaialble for the shots data set about how shot_dist is measured
#corner threes are 22ft from the center of the rim to the line, which allows for instances of three pt shots shorter than 22 (e.g., foot on the line but called a three, shot_dist is measured from "front" of the rim)
shots %>% filter(PTS_TYPE == 3 & SHOT_DIST < 21) %>% nrow(.)
shots %>% filter(PTS_TYPE == 3 & SHOT_DIST < 21.5) %>% nrow(.)
shots %>% filter(PTS_TYPE == 3 & SHOT_DIST < 22) %>% nrow(.)
shots %>% filter(PTS_TYPE == 2 & SHOT_DIST > 24) %>% nrow(.)
shots %>% filter(PTS_TYPE == PTS) %>% group_by(SHOT_RESULT) %>% count()
#pts_type and pts match unless the shot was missed
#It is possible that pts_type is not a useful predictor beyond a measure of distance etc...
#so I can choose to drop some or all or just drop "obvious" errors and recode others or not include pts_type in the model at all, but its probably best to recode and preserve as much data as possible
#recoding
#in both cases of recoding pts_type it is difficult to decide on a cutoff, but the longest point of the nba 3pt line is 23'9" and the shortest is 22' so given the possibility that the shot distance is measured to the front of the rim (not the center of the basket like the 3pt line) some what conservative cutoffs will be used
shots[shots$PTS_TYPE == 2 & shots$SHOT_DIST > 24, 13] <- 3
shots[shots$PTS_TYPE == 3 & shots$SHOT_DIST < 21.5, 13] <- 2
#Although all shots are recorded as no farther than half court, at least some of those shots don't represent "meaningful" attempts - that is, shots around half court are not part of any offensive scheme and even the best shooters typically don't shoot from further than 30 feet (with some exceptions)
shots %>% group_by(PTS_TYPE) %>% summarize(ave_dist = mean(SHOT_DIST), sd_dist = sd(SHOT_DIST))
#To be conservative and keep shots within about 4 sds of the mean 3pt distance places the cutoff at 32
shots %>% filter(SHOT_DIST > 32) %>% group_by(player_name) %>% count() %>% arrange(desc(`n`))
shots %>% filter(SHOT_DIST > 32) %>% nrow(.)
shots %>% filter(SHOT_DIST < 1) %>% nrow(.)
#0 isn't a meaningful shot distance and doesn't represent tip-ins there should be more than 4 if that were the case
shots <- shots %>% filter(!(SHOT_DIST > 32 | SHOT_DIST == 0))
#
#fix defender names
shots_ranges$CLOSEST_DEFENDER
#defender names do not match the format of player name
#check that all defender names are in the same format
commas <- str_which(shots$CLOSEST_DEFENDER, ",")
all <- row_number(shots$CLOSEST_DEFENDER)
no_commas <- setdiff(all, commas)
unique(shots[no_commas, 15])
#nene is one name without comma
#fix nene in order to reformat all names
shots$CLOSEST_DEFENDER <- str_replace(shots$CLOSEST_DEFENDER, "Nene", "Hilario, Nene")
defend <- str_split(shots$CLOSEST_DEFENDER, ", ")
  nms <- c("last_name", "first_name")
  defender_names <- data_frame(map_chr(defend, 1),
                       map_chr(defend, 2)) %>%
    setNames(nms) %>%
    mutate(player_name = str_c(first_name, last_name, sep = " "))
  anti_join(defender_names, positions, by = "player_name") %>% distinct(player_name)
  ###drop atila dos santos shots - no proof he played
no_match_defenders <- anti_join(defender_names, positions, by = "player_name") %>% distinct(player_name) %>% filter(player_name != "Atila Dos Santos")
fixed_pname_def <- c("J.J. Barea", "C.J. Miles", "C.J. Watson", "J.J. Hickson", "Tim Hardaway", "J.J. Redick", "P.J. Tucker", "K.J. McDaniels", "C.J. Wilcox", "P.J. Hairston", "Jeffery Taylor", "Luigi Datome", "Chuck Hayes", "Glen Rice", "T.J. Warren", "Toure' Murry")
defender_names$player_name<- plyr::mapvalues(defender_names$player_name, from = no_match_defenders$player_name, to = fixed_pname_def)
shots <- shots %>% filter(CLOSEST_DEFENDER != "Dos Santos, Atila")
defend1 <- str_split(shots$CLOSEST_DEFENDER, ", ")
shots <- shots %>% mutate(last_name = map_chr(defend1, 1), first_name = map_chr(defend1, 2))
shots$CLOSEST_DEFENDER <- str_c(shots$first_name, shots$last_name, sep = " ")
shots$CLOSEST_DEFENDER<- plyr::mapvalues(shots$CLOSEST_DEFENDER, from = no_match_defenders$player_name, to = fixed_pname_def)
#####now join positions to defender names
anti_join(shots, positions, by = c("CLOSEST_DEFENDER" = "player_name")) %>% select(CLOSEST_DEFENDER)
#player_id and defender_id are not being used, but there was a duplicate defender_id for quincy pondexter...
shots <- shots %>% left_join(positions, by = "player_name") %>% left_join(positions, by = c("CLOSEST_DEFENDER" = "player_name")) %>% rename("POS_DEF" = "Pos.y", "POS_SHOOTER" = "Pos.x", "rid_DEF" = "rid.y", "rid_SHOOTER" = "rid.x") %>% select(-c(last_name, first_name, player_id, CLOSEST_DEFENDER_PLAYER_ID))
#i want to create a "mismatch" measure from position. I will attempt to keep it as simple as possible but will do some exploring.
shots$POS_SHOOTER <- case_when(shots$POS_SHOOTER == "PG" ~ 1, shots$POS_SHOOTER == "SG" ~ 2, shots$POS_SHOOTER == "SF" ~ 3, shots$POS_SHOOTER == "PF" ~ 4, shots$POS_SHOOTER == "C" ~ 5)
shots$POS_DEF <- case_when(shots$POS_DEF == "PG" ~ 1, shots$POS_DEF == "SG" ~ 2, shots$POS_DEF == "SF" ~ 3, shots$POS_DEF == "PF" ~ 4, shots$POS_DEF == "C" ~ 5)
shots <- shots %>% mutate(MISMATCH = POS_SHOOTER - POS_DEF)
#
#
# will need to do this shots <- shots %>% mutate_if(is.character, as.factor)
```
#some exploratory visualizations and alterations
```{r exploratory visualizations}
library(cowplot)
library(GGally)
#some crude, but potentially useful plots
#cowplot is easy to view on one page, but will also loop through multiple pages
index_num <- map_lgl(shots, is.numeric)
names_num <- names(shots[, index_num])
plot_lst <- list()
for(i in names_num){
  plt <- ggplot(shots, aes_string(x=i)) +
    geom_histogram()
  plot_lst[[i]] <- plt
}
cowplot::plot_grid(plotlist = plot_lst, nrow = 4)
list_num_plots <- map(plot_lst, print)
#most games are close with bimodal around 0, some "step" patter in number of shots, very few overtime games, relatively normal distr of shot clock with many at 24 (likely off rebounds), most dribbles under 5 short touch time, shots seem to match "modern" nba with most either close or far with relatively few midrange, doesn't seem to be data error in reporting pts type (at least in putting a number other than 2 or 3), most shots occur with a defender with 5 or so feet, fgm is either 1 or 0
#now look at "important" variables
names_num_variables <- names_num[-c(1, 2, 10, 14, 16, 17)]
cor(shots[, names_num_variables], use = "complete.obs")
ggcorr(shots[, names_num_variables], label = TRUE, hjust = 0.75, size = 3, layout.exp = 2)
ggplot(shots, aes(SHOT_DIST, CLOSE_DEF_DIST)) +
  geom_point()
shots %>% mutate_at("PTS_TYPE", as.factor) %>%
  ggplot(aes(SHOT_DIST, CLOSE_DEF_DIST)) +
  geom_point(aes(color = PTS_TYPE))
##it seems that as shot distance increases so does the distance of the defender (except very close to basket, which is likley to represent breakaways and/or defensive breakdowns/miscommunications), until the three point line and then from there denfender tend to be closer for deeper shots
shots %>% mutate_at("PTS_TYPE", as.factor) %>%
  ggplot(aes(PTS_TYPE, CLOSE_DEF_DIST)) +
  geom_violin()
#however defenders still tend to be further away for 3pt shots, but not necessarily for "deep" 3pt shots 
shots %>%
  ggplot(aes(TOUCH_TIME, CLOSE_DEF_DIST)) +
  geom_point()
#very few long touch times when a defender is far away (some might represent end of game situations when the ball is held for time purposes) and generally defenders are close when touch time is long
shots %>%
  ggplot(aes(SHOT_DIST, TOUCH_TIME)) +
  geom_point()
shots %>%
  ggplot(aes(SHOT_DIST, TOUCH_TIME)) +
  geom_point() +
  facet_wrap(~ MISMATCH, nrow = 3)
#seems "big men" moight tend to touch it less
shots %>%
  ggplot(aes(TOUCH_TIME)) +
  geom_freqpoly() +
  facet_wrap(~POS_SHOOTER)
#PGs have the most "long" touches
shots %>% 
  ggplot(aes(SHOT_DIST)) +
  geom_density() +
  facet_wrap(~MISMATCH)
#mismatches tend to occur close to the hoop which makes sense since centers and pgs would be consistenlty close there whether in a post up or drive to the hoop and "centers"big men"" should generally be closer to the hoop 
shots %>%
  ggplot(aes(POS_DEF, SHOT_DIST)) +
  geom_boxplot(aes(group = POS_DEF))
#which was shown in the boxplot
#dribbles and touch time have a strong corrlation (but I will include both in the models below for now - won't hurt predictions)
shots %>%
  ggplot(aes(DRIBBLES, TOUCH_TIME)) +
  geom_point() +
  facet_wrap(~MISMATCH)
colnames(shots[, !index_num])
```
#some modeling "doodles" - Logistic Regression
```{r modeling_begins}
library(caret)
###logistic regression without creating anykind of position variable, just an interaction
shots <- shots %>% mutate_at(c("SHOT_RESULT", "LOCATION"), as.factor) %>% mutate(SHOT_NUMERIC = as.numeric(SHOT_RESULT == "made"))
test_index_glm <- createDataPartition(shots$SHOT_NUMERIC, times = 1, p = 0.5, list = FALSE)
train_set_glm_shots <- shots %>% slice(-test_index_glm)
test_set_glm_shots <- shots %>% slice(test_index_glm)
#now fit a model
fit_glm_shots <- glm(SHOT_NUMERIC ~ qtr_seconds + LOCATION + SHOT_NUMBER + PERIOD + SHOT_CLOCK + DRIBBLES + TOUCH_TIME + PTS_TYPE + CLOSE_DEF_DIST*SHOT_DIST*MISMATCH, data = train_set_glm_shots, family = "binomial")
p_hat_glm_shots <- predict(fit_glm_shots, test_set_glm_shots)
y_hat_glm_shots <- factor(ifelse(p_hat_glm_shots > 0.5, "made", "missed"))
summary(fit_glm_shots)
confusionMatrix(data = y_hat_glm_shots, reference = test_set_glm_shots$SHOT_RESULT)
```
#some modeling "doodles" - Random Forest
```{r modeling_2}
library(randomForest)
library(ranger)
nearZeroVar(train_set_glm_shots)
na_index <- is.na(shots$SHOT_CLOCK)
shots$SHOT_CLOCK <- if_else(na_index, shots$qtr_seconds, shots$SHOT_CLOCK)
variables_to_use <- shots %>% select(qtr_seconds, LOCATION, SHOT_NUMBER, PERIOD, SHOT_CLOCK, DRIBBLES, TOUCH_TIME, PTS_TYPE, CLOSE_DEF_DIST, SHOT_DIST, MISMATCH) %>% names(.)
test_index_RF <- createDataPartition(shots$SHOT_NUMERIC, times = 1, p = 0.5, list = FALSE)
train_set_RF <- shots %>% slice(-test_index_RF) %>% select(variables_to_use, SHOT_RESULT)
test_set_RF <- shots %>% slice(test_index_RF) %>% select(variables_to_use, SHOT_RESULT)
#train_rf <- randomForest(SHOT_RESULT ~ qtr_seconds + SHOT_CLOCK + DRIBBLES + TOUCH_TIME + PTS_TYPE + CLOSE_DEF_DIST*SHOT_DIST*MISMATCH, data = train_set_RF)
#model_ranger <- ranger(SHOT_RESULT ~ .)
control_RF <- trainControl(method="cv", number = 4, p = 0.8)
train_rf_tuned <-  train(SHOT_RESULT ~ ., data = train_set_RF,
                   method = "ranger", 
                   tuneGrid = expand.grid(.mtry = 2:6, .splitrule = "gini", .min.node.size = c(1)),
                   num.trees = 100,
                   trControl = control_RF)
##train_rf_tuned works
train_rf_no_tuned <-  train(SHOT_RESULT ~ ., data = train_set_RF,
                   method = "ranger", 
                   num.trees = 100,
                   trControl = control_RF)
##also works without grid...
fit_rf_ranger <- ranger(SHOT_RESULT ~ ., data = train_set_RF, 
                  num.trees = 1000,
                  min.node.size = train_rf_no_tuned$bestTune$min.node.size,
                  mtry = train_rf_no_tuned$bestTune$mtry,
                  splitrule = train_rf_no_tuned$bestTune$splitrule)
y_hat_rf <- predict(fit_rf_ranger, test_set_RF)
cm_rf <- confusionMatrix(y_hat_rf$predictions, test_set_RF$SHOT_RESULT)
#####left off, the high rate is 68% with gradient boosting
library(gbm)
train_boost_no_tuned <- train(SHOT_RESULT ~ ., data = train_set_RF,
                   method = "gbm")
##gbm took forever and still only got to .6191 so switched to a tuned xgboost instead...need to convert to 0,1 even for gbm
########
library(xgboost)
#this will not be needed if slice is not masked by xgboost package
train_set_RF_noslice <- shots[-test_index_RF, c('SHOT_RESULT', variables_to_use)]
test_set_RF_noslice <- shots[test_index_RF, c('SHOT_RESULT', variables_to_use)]
train_set_RF_noslice <- train_set_RF_noslice %>% mutate(SHOT_RESULT = as.numeric(SHOT_RESULT == "made"), LOCATION = as.numeric(LOCATION == "H"))
test_set_RF_noslice <- test_set_RF_noslice %>% mutate(SHOT_RESULT = as.numeric(SHOT_RESULT == "made"), LOCATION = as.numeric(LOCATION == "H"))
head(train_set_RF_noslice)
head(test_set_RF_noslice)
#
xg_labels_train <- train_set_RF_noslice$SHOT_RESULT
xg_labels_test <- test_set_RF_noslice$SHOT_RESULT
trainer <- as.matrix(train_set_RF_noslice[, -1])
tester <- as.matrix(test_set_RF_noslice[, -1])
matrix_train_xgboost <- xgb.DMatrix(data = trainer,label = xg_labels_train)
matrix_test_xgboost <- xgb.DMatrix(data = tester,label= xg_labels_test)
#
params_default_xgboost <- list(booster = "gbtree", objective = "binary:logistic", eta=0.3, gamma=0, max_depth=6, min_child_weight=1, subsample=1, colsample_bytree=1)
xgbcv <- xgb.cv( params = params_default_xgboost, data = matrix_train_xgboost, label = xg_labels_train, nrounds = 100, nfold = 5, showsd = T, stratified = T, print_every_n = 10, early_stop_round = 20, maximize = F)
xgbcv$evaluation_log$iter[xgbcv$evaluation_log$test_error_mean == min(xgbcv$evaluation_log$test_error_mean)]
#
xgb_grid_1 <- expand.grid(eta = c(0.01, 0.05, 0.1, 0.3),  
                            colsample_bytree=c(0.5,0.7),
                            max_depth=c(3,4),
                            nrounds= c(100),
                            gamma=1,
                            min_child_weight=c(0.0001, 0.001, 0.01, .1, 1),
                            subsample= c(0.2, 0.5, 0.8)
                            )

xgb_trcontrol <- trainControl(
  method="cv",
  number = 5,
  verboseIter = TRUE,
  returnData=FALSE,
  returnResamp = "all",
  allowParallel = TRUE
)

xgb_train_1 <- train(
  x = matrix_train_xgboost,
  y= as.factor(xg_labels_train),
 trControl = xgb_trcontrol,
 tuneGrid = xgb_grid_1,
 method="xgbTree"
)
xgb_train_1
###Tuning parameter 'nrounds' was held constant at a value of 100
##Tuning parameter 'gamma' was held constant
 ##at a value of 1
###Accuracy was used to select the optimal model using the largest value.
###The final values used for the model were nrounds = 100, max_depth = 4, eta = 0.1, gamma = 1,
 ###colsample_bytree = 0.7, min_child_weight = 0.001 and subsample = 0.5.
xgb_shots <- xgboost(data = matrix_train_xgboost, label = as.factor(xg_labels_train), params = xgb_train_1$bestTune, nrounds = 1000)
xgb_predictions <- predict(xgb_shots, as.matrix(test_set_RF_noslice[, -1]))
xgb_predictions <- if_else(xgb_predictions > .5, 1, 0)
confusionMatrix(as.factor(xgb_predictions), as.factor(test_set_RF_noslice$SHOT_RESULT))
#
#xgb_cheat <- xgboost(data = matrix_train_xgboost, label = as.factor(xg_labels_train), eta = 0.0001, max_depth = 3, min_child_weight = .0001, nrounds = 1000, gamma = 1, subsample = 0.5)
#xgb_predictions_cheat <- predict(xgb_cheat, as.matrix(test_set_RF_noslice[, -1]))
#xgb_predictions_cheat <- if_else(xgb_predictions > .5, 1, 0)
#confusionMatrix(as.factor(xgb_predictions_cheat), as.factor(test_set_RF_noslice$SHOT_RESULT))
xgb_mod_nodes <- xgb.dump(xgb_shots, with_stats = TRUE)
xgb_mod_nodes[1:10]
xgb_names <- names(test_set_RF_noslice[, -1])[[2]]
importance_matrix <- xgb.importance(xgb_names, model = xgb_shots)
xgb.plot.importance(importance_matrix)
```
